# Report

## 基本思路

本实验需要实现的是四子棋的人工智能算法来进行AI之间的相互对抗。基本思路是使用课上学习过的蒙特卡洛树搜索MCTS，并使用UCB1算法后得到的信心上限树算法UCT。即：

从当前状态开始，只要还未到时间上限，便继续迭代过程。

每一轮迭代过程首先会根据每个节点计算得出的UCB1值，选取一个拓展的节点。然后对于拓展的节点进行一个随机模拟，并得到一个收益，然后将该份收益从拓展节点往上传递，并进行下一次迭代。

## 实现方法

在 `TreeNode.hpp` 中定义了结构体 `TreeNode` ，用于储存搜索树中的节点。每一个节点中保存有以下信息：

``` C++
struct TreeNode
{
	int M, N;
	double win;
	int tot;
	bool self;
	int **board;
	int *top;
	int x, y;
	int ava_ch, exp_ch;
	int noX, noY;
	TreeNode *fa;
	TreeNode **ch;
};
```

并且实现了相应的一些方法： `terminal` 调用了 `Judge.h` 中定义的相关函数，用于判断该节点储存的棋盘局势是否有玩家胜出或平局。 `all_expanded` 用于判断当前节点是否已经拓展过所有可能的孩子节点。 `expand` 用于拓展当前节点的某个未拓展过的孩子。 `rollout` 用于对当前节点进行随机模拟到终局，并返回收益。 `print` 用于在调试过程中输出树的相关信息。

在 `SingleChoice.hpp` 中定义了 `SingleChoice` 函数，用于判断当前局面是否有单个最优步。该函数判断了以下情况：

1. 对于每一个能走的步，是否能直接让自己赢，若能，则下一步下在此处。
2. 对于每一个能走的步，对方下在此处是否能直接赢，若能，则下一步下在此处。

在 `Strategy.cpp` 中， `getPoint` 函数获取相关信息后，会调用 `UctSearch` 进行搜索。按照[基本思路](基本思路)中的算法，其中选择拓展节点是通过调用 `select` 函数来实现的，若当前节点未拓展完，则使用当前节点的 `expand` 方法来拓展一个孩子节点，若已经拓展完，则使用UCB1值来选取最优的孩子来继续选取。选取完节点后，就使用节点的 `rollout` 方法来产生收益，并向上传递收益一直到树根。

需要进行调参的参数只有计算UCB1值时惩罚项用到的 $C$ 值。经过测试后，发现 $C$ 取 $0.55, 0.6, 0.65` 后的结果相近，最终选择 $C=0.65$

## 评测结果

使用批量测试后，得到在偶数测试点上的胜率为 $91\%$
